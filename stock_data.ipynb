{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "@Author: Rashmi\n",
    "@Date: 2021-12-11 19:31\n",
    "@Last Modified by: Rashmi\n",
    "@Last Modified time: 2021-12-11  00:30\n",
    "@Title :Program Aim is to clean and preprocess the data by fetching real time stock data using API key, Spark and then create a dataframe and build a machine learning model. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:51:11,277 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "from json import dumps\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.functions import percent_rank\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"Stock Data Prediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol=IBM&interval=15min&slice=year1month1&apikey= key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The api key data is stored in csv file and that file sent to hdfs through terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.Session() as s:\n",
    "    download = s.get(CSV_URL)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "    my_list = list(cr)\n",
    "with open('data.csv', 'w') as csv_file: \n",
    "    csv_writer = csv.writer(csv_file, delimiter=\",\")\n",
    "    for row in my_list:\n",
    "        csv_writer.writerow(row)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the stock data csv file from hdfs and stored it as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Row(time='2021-12-10 20:00:00', open='124.02', high='124.02', low='124.02', close='124.02', volume='151')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(\"hdfs://localhost:9000/project-stockdata/data.csv\",header=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, time: string, open: string, high: string, low: string, close: string, volume: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------+------+------+\n",
      "|               time|  open|  high|   low| close|volume|\n",
      "+-------------------+------+------+------+------+------+\n",
      "|2021-12-10 20:00:00|124.02|124.02|124.02|124.02|   151|\n",
      "|2021-12-10 19:45:00|124.24|124.24|124.24|124.24|   279|\n",
      "|2021-12-10 19:15:00|123.85|123.85|123.85|123.85|   499|\n",
      "|2021-12-10 19:00:00|123.94|123.94|123.94|123.94|   117|\n",
      "+-------------------+------+------+------+------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casting the string values to double to prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\\\n",
    "    .withColumn(\"open\",col(\"Open\").cast(\"double\"))\\\n",
    "    .withColumn(\"high\",col(\"High\").cast(\"double\"))\\\n",
    "    .withColumn(\"low\",col(\"Low\").cast(\"double\"))\\\n",
    "    .withColumn(\"close\",col(\"Close\").cast(\"double\"))\\\n",
    "    .withColumn(\"volume\",col(\"Volume\").cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(time='2021-12-10 20:00:00', open=124.02, high=124.02, low=124.02, close=124.02, volume=151.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Creating the vectors from features. Apache MLib takes the input in the form of vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|features              |\n",
      "+----------------------+\n",
      "|[124.02,124.02,124.02]|\n",
      "|[124.24,124.24,124.24]|\n",
      "|[123.85,123.85,123.85]|\n",
      "|[123.94,123.94,123.94]|\n",
      "|[124.09,124.09,123.85]|\n",
      "+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureassembler=VectorAssembler(inputCols=[\"open\",\"high\",\"low\"],outputCol=\"features\")\n",
    "output=featureassembler.transform(df2)\n",
    "output.select(\"features\").show(5,truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------+\n",
      "|               time|            features| close|\n",
      "+-------------------+--------------------+------+\n",
      "|2021-11-11 05:00:00|[120.56,120.56,12...|120.56|\n",
      "|2021-11-11 05:45:00|[120.93,120.93,12...|120.93|\n",
      "|2021-11-11 06:15:00|[120.87,120.87,12...|120.85|\n",
      "|2021-11-11 06:45:00|[120.78,120.78,12...|120.78|\n",
      "|2021-11-11 07:15:00|[120.64,120.65,12...|120.65|\n",
      "+-------------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data=output.select(\"time\",\"features\",\"close\").sort(\"time\",ascending=True)\n",
    "finalized_data.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and testing data and Final data for real time stock data created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = finalized_data.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(\"time\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:52:46,210 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------+\n",
      "|               time|            features| close|\n",
      "+-------------------+--------------------+------+\n",
      "|2021-11-11 05:00:00|[120.56,120.56,12...|120.56|\n",
      "|2021-11-11 05:45:00|[120.93,120.93,12...|120.93|\n",
      "|2021-11-11 06:15:00|[120.87,120.87,12...|120.85|\n",
      "|2021-11-11 06:45:00|[120.78,120.78,12...|120.78|\n",
      "|2021-11-11 07:15:00|[120.64,120.65,12...|120.65|\n",
      "|2021-11-11 07:30:00| [120.7,120.7,120.7]| 120.7|\n",
      "|2021-11-11 07:45:00|[120.65,120.87,12...|120.79|\n",
      "|2021-11-11 08:15:00|[120.75,120.75,12...| 120.7|\n",
      "|2021-11-11 08:30:00|[120.64,120.78,12...|120.78|\n",
      "|2021-11-11 08:45:00|[120.64,120.64,12...| 120.4|\n",
      "+-------------------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "'''storing 80% of actual data into train dataframe'''\n",
    "train_df = final_data.where(\"rank <= .8\").drop(\"rank\")\n",
    "train_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:52:53,812 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:52:57,701 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------+\n",
      "|               time|            features| close|\n",
      "+-------------------+--------------------+------+\n",
      "|2021-12-06 15:45:00|[120.085,120.18,1...|120.04|\n",
      "|2021-12-06 16:00:00|[120.05,120.17,11...|119.95|\n",
      "|2021-12-06 16:15:00|[119.91,120.05,11...|120.05|\n",
      "|2021-12-06 16:30:00| [119.9,119.9,119.9]| 119.9|\n",
      "|2021-12-06 16:45:00|[119.95,120.0,119...| 120.0|\n",
      "|2021-12-06 17:00:00|[120.0,120.0,119.77]|119.77|\n",
      "|2021-12-06 17:45:00|[119.84,119.91,11...|119.84|\n",
      "|2021-12-06 18:00:00|[120.05,120.05,12...|120.05|\n",
      "|2021-12-06 18:30:00| [120.0,120.0,120.0]| 120.0|\n",
      "|2021-12-06 19:00:00|[119.99,119.99,11...|119.99|\n",
      "+-------------------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_df = final_data.where(\"rank > .8\").drop(\"rank\")\n",
    "test_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:53:03,904 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:56:02,304 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "'''stores in hdfs at /user/lenovo/testdata'''\n",
    "test_df.write.parquet('testdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a ML Model (Linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:54:10,768 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-01-05 00:54:11,257 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2022-01-05 00:54:11,483 WARN util.Instrumentation: [ec343b84] regParam is zero, which might cause numerical instability and overfitting.\n",
      "2022-01-05 00:54:13,148 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2022-01-05 00:54:13,151 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2022-01-05 00:54:13,225 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2022-01-05 00:54:13,226 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "2022-01-05 00:54:13,404 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.6116892987793721,0.7903863219989552,0.8207568446262014]\n",
      "Intercept: 0.0689714373998241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "linear_reg=LinearRegression(featuresCol='features',labelCol='close')\n",
    "lr_model=linear_reg.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:54:20,173 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|            features| close|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|[120.085,120.18,1...|120.04|120.05267368422624|\n",
      "|[120.05,120.17,11...|119.95|119.96768812510837|\n",
      "|[119.91,120.05,11...|120.05|120.02413881586769|\n",
      "| [119.9,119.9,119.9]| 119.9|119.90349019210937|\n",
      "|[119.95,120.0,119...| 120.0|119.99298220160162|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "predDF = lr_model.transform(test_df)\n",
    "predDF.select(\"features\", \"close\",\"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model using Regression Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:54:28,043 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error(RMSE) is 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "predictionCol=\"prediction\",\n",
    "labelCol=\"close\",\n",
    "metricName=\"rmse\")\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "print(f\"Root Mean Squared Error(RMSE) is {rmse:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Save the model to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.save(\"hdfs://localhost:9000/prediction_stock_price_data_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 01:00:06,869 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "# test_df.write.parquet('testdata')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
